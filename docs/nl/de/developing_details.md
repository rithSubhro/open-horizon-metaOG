---

copyright:
years: 2021
lastupdated: "2021-02-20"

---

{:new_window: target="blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:codeblock: .codeblock}
{:pre: .pre}
{:child: .link .ulchildlink}
{:childlinks: .ullinks}

# Details zur Entwicklung
{: #developing}

Im folgenden Inhalt werden weiterführende Details zu den Verfahren und Konzepten der Softwareentwicklung für {{site.data.keyword.edge_notm}} ({{site.data.keyword.edge_abbr}}) bereitgestellt.
{:shortdesc}

## Einführung
{: #developing_intro}

{{site.data.keyword.edge_notm}} ({{site.data.keyword.edge_abbr}}) wird auf der Open-Source-Software von [Open Horizon](https://www.lfedge.org/projects/openhorizon/) erstellt.

Mit {{site.data.keyword.ieam}} können Sie sämtliche Service-Container entwickeln, die Sie für Ihre Edge-Maschinen benötigen. Anschließend können Sie die Containerkonfiguration kryptographisch signieren und veröffentlichen. Abschließend können Sie Ihre Service-Container mithilfe einer Implementierungsrichtlinie oder eines Musters implementieren, um die Softwareinstallation, -überwachung und -aktualisierung zu steuern. Nachdem Sie diese Tasks abgeschlossen haben, können Sie die {{site.data.keyword.horizon_agents}} und {{site.data.keyword.horizon_agbots}} anzeigen, die die Vereinbarungen für die Zusammenarbeit beim Management des Softwarelebenszyklus treffen. Diese Komponenten verwalten die Details des Software-Lebenszyklus autonom auf Ihrem {{site.data.keyword.edge_nodes}}. {{site.data.keyword.ieam}} kann auch Richtlinien verwenden, um maschinelle Lernmodelle autonom zu implementieren. Informationen zur Implementierung des Modells für maschinelles Lernen finden Sie unter [Model Management System](model_management_system.md).

Der Softwareentwicklungsprozess in {{site.data.keyword.ieam}} dient primär der Aufrechterhaltung der Systemsicherheit und -integrität und trägt gleichzeitig zur deutlichen Vereinfachung des Aufwands bei, der für das aktive Software-Management auf Ihren Edge-Knoten anfällt. Sie können Publizierungsprozeduren für {{site.data.keyword.ieam}} in Ihre kontinuierliche Integrations- und Entwicklungspipeline aufnehmen. Wenn die verteilten autonomen Agenten publizierte Änderungen in der Software oder in einer Richtlinie erkennen, z. B. in der {{site.data.keyword.edge_deploy_pattern}} oder in der Implementierungsrichtlinie, agieren die autonomen Agenten unabhängig voneinander, um die Software zu aktualisieren und Ihre Richtlinien über Ihre gesamte Flotte von Edge-Maschinen zu erzwingen, wo immer sie sich befinden.

## Services
{: #services_deploy_patterns}

{{site.data.keyword.edge_services}} sind die Bausteine von Edge-Lösungen. Jeder Service enthält einen oder mehrere Docker-Container. Jeder Docker-Container kann wiederum einzelne oder mehrere Prozesse mit langer Laufzeit enthalten. Diese Prozesse können in nahezu allen Programmiersprachen geschrieben werden und verwenden alle Bibliotheken oder Dienstprogramme. Allerdings müssen die Prozesse für den Kontext eines Docker-Containers entwickelt und in diesem Kontext ausgeführt werden. Diese Flexibilität bedeutet, dass nahezu keine Einschränkungen in Bezug auf den Code gelten, den {{site.data.keyword.ieam}} für Sie verwalten kann. Wenn ein Container ausgeführt wird, dann befindet sich dieser Container in einer sicheren Sandbox. Diese Sandbox schränkt den Zugriff auf Hardwareeinheiten, einige Betriebssystemservices, das Hostdateisystem, die Host-Edge-Maschinennetze und vor allem andere Services, die auf dem Edge-Knoten ausgeführt werden, ein. Informationen zu den geltenden Sandboxeinschränkungen finden Sie im Abschnitt zur [Sandbox](#sandbox).

Der Beispielcode `cpu2evtstreams` besteht aus einem Docker-Container, der zwei andere Edge-Services verwendet. Diese Edge-Services stellen über HTTP-REST-APIs eine Verbindung über lokale private Docker-virtuelle Netze her. Die Namen dieser Services lauten `cpu` und `gps`. Der Agent stellt jeden dieser Services zusammen mit allen Services, die eine Abhängigkeit zu dem jeweiligen Service deklariert haben, in einem separaten privaten Netz bereit. Ein Netz wird für `cpu2evtstreams` und `cpu` erstellt, ein weiteres Netz für `cpu2evtstreams` und `gps`. Wenn in dieser Implementierung ein vierter Service vorhanden ist, der auch den Service `cpu` gemeinsam verwendet, wird ein weiteres privates Netz für nur `cpu` und den vierten Service erstellt. In {{site.data.keyword.ieam}} dient diese Netzstrategie zur Einschränkung des Zugriffs der Services, sodass diese nur auf die anderen Services zugreifen können, die unter `requiredServices` aufgelistet werden, wenn die anderen Services publiziert werden. Das folgende Diagramm zeigt die Implementierung von `cpu2evtstreams` , wenn das Muster auf einem Edge-Knoten ausgeführt wird:

<img src="../images/edge/07_What_is_an_edge_node.svg" style="margin: 3%" alt="Services in einem Muster">

Hinweis: Die Einrichtung von IBM Event Streams ist nur für bestimmte Beispiele erforderlich.

Die beiden virtuellen Netze ermöglichen dem Service-Container für `cpu2evtstreams` den Zugriff auf die REST-APIs, die von den Service-Containern für `cpu` und `gps` bereitgestellt werden. Diese beiden Container verwalten den Zugriff auf die Betriebssystemservices und die Hardwareeinheiten. Obwohl REST-APIs verwendet werden, bestehen noch zahlreiche andere Kommunikationsmöglichkeiten, die Sie verwenden können, um Ihren Services die gemeinsame Nutzung der Daten und der Steuerungsfunktionen zu ermöglichen.

Häufig erweist sich als effektivstes Codemuster für Edge-Knoten die Bereitstellung mehrerer kleiner, unabhängig voneinander konfigurierbarer und bereitstellbarer Services. IoT-Muster (IoT = Internet of Things; Internet der Dinge) arbeiten häufig mit Low-Level-Services, die Zugriff auf die Hardware der Edge-Knoten benötigen. Hierzu gehören beispielsweise Sensoren oder Aktuatoren. Diese Services ermöglichen den gemeinsamen Zugriff auf diese Hardwarekomponenten, die somit von anderen Services genutzt werden können.

Dieses Muster ist dann nützlich, wenn die Hardware exklusiven Zugriff benötigt, um eine sinnvolle Funktion bereitstellen zu können. Der Low-Level-Service kann diese Form des Zugriffs ordnungsgemäß verwalten. Die Rolle der Service-Container für `cpu` und `gps` ähnelt der der Einheitentreibersoftware im Betriebssystem des Hosts, jedoch auf höherer Ebene. Die Segmentierung des Codes in unabhängige kleine Services, wobei einige speziell für den Low-Level-Hardwarezugriff dienen, ermöglicht eine klare Trennung der Zuständigkeiten (sog. Separation of Concerns). Jede Komponente kann frei entwickelt und im Feld unabhängig aktualisiert werden. Drittanbieteranwendungen können ohne Risiko gemeinsam mit Ihren proprietären konventionellen eingebetteten Software-Stacks bereitgestellt werden. Hierzu wird diesen Komponenten selektiv der Zugriff auf bestimmte Hardwareeinheiten oder andere Services ermöglicht.

Beispielsweise kann sich eine Implementierung eines industriellen Controllers aus einem Service mit einer niedrigen Ebene für die Überwachung von Leistungssensoren und anderen Services mit niedriger Leistung zusammensetzen. Diese anderen Low-Level-Services können zur Steuerung der Aktuatoren zur Stromversorgung der Einheiten genutzt werden, die überwacht werden sollen. Die Implementierung verfügt möglicherweise auch über einen anderen Service-Container der höchsten Ebene, der die Services des Sensors und des Aktuators verbraucht. Dieser Top-Level-Service kann die Services zur Benachrichtigung der Operatoren oder zur automatischen Stromabschaltung bei Einheiten nutzen, wenn ein von der Norm abweichender Stromverbrauchswert gemessen wird. Diese Implementierung kann auch einen Verlaufsservice umfassen, der Sensor-und Aktuatordaten erfasst und archiviert und möglicherweise eine vollständige Analyse der Daten ermöglicht. Andere nützliche Komponenten einer solchen Implementierung könnten ein GPS-Standortservice sein.

Jeder einzelne Service-Container kann mit diesem Design unabhängig versioniert und aktualisiert werden. Jeder einzelne Service kann auch rekonfiguriert und in andere nützliche Implementierungen ohne Codeänderungen zusammengesetzt werden. Falls erforderlich, kann der Implementierung ein Analyseservice eines anderen Anbieters hinzugefügt werden. Dieser Service von Drittanbietern kann nur auf eine bestimmte Gruppe von schreibgeschützten APIs zugreifen, wodurch verhindert wird, dass der Service mit den Aktoren auf der Plattform interagieren kann.

Alternativ hierzu können alle Tasks in diesem Beispiel einer industriellen Steuereinheit in einem einzelnen Service-Container ausgeführt werden. Diese Alternative stellt allerdings meist nicht den besten Ansatz dar, da eine Gruppe kleinerer unabhängiger und miteinander verbundener Services normalerweise eine schnellere Softwareaktualisierung ermöglicht und ein höheres Maß an Flexibilität bietet. Gruppen kleinerer Services bieten häufiger auch eine geringere Störanfälligkeit im Feld. Weitere Informationen zum Design einer Implementierung finden Sie unter [Edge-native Entwicklungspraktiken](best_practices.md).

## Sandbox
{: #sandbox}

Die Sandbox, in der Implementierungen ausgeführt werden, schränkt den Zugriff auf APIs ein, die von anderen Servicecontainern bereitgestellt werden. Nur den Services, in denen explizit Abhängigkeiten von Ihren Services deklariert sind, wird der Zugriff erteilt. Andere Prozesse auf dem Host sind nicht in der Lage, auf diese Services zuzugreifen. In ähnlicher Weise können andere ferne Hosts keinen Zugriff auf Ihre Services haben, es sei denn, Ihr Service veröffentlicht explizit einen Port für die externe Netzschnittstelle des Hosts. Die Zugriffskontrollbeschränkungen der Sandbox werden durch die Netzadressierbarkeit bestimmt, nicht durch eine verwaltete Zugriffssteuerungsliste. Dies wird durch die Erstellung virtueller Netze für jeden Service unterstützt, und nur Servicecontainer, die kommunizieren dürfen, sind mit demselben Netz verbunden. Dadurch wird die Notwendigkeit, die Zugriffssteuerung für jeden Edge-Knoten zu konfigurieren, verringert.

## Services, die andere Services verwenden
{: #using_services}

Edge-Services verwenden häufig verschiedene API-Schnittstellen, die von anderen Edge-Services bereitgestellt werden, um Daten von diesen anzufordern oder Steuerbefehle an sie zu senden. Diese API-Schnittstellen sind im Allgemeinen HTTP-REST-APIs, wie diejenigen, die von den Low-Level-Services `cpu` und `gps` im Beispiel `cpu2evtstreams` bereitgestellt werden. Allerdings kann der Einsatz dieser Schnittstellen tatsächlich sinnvoll sein, z. B. für gemeinsam genutzten Speicher, TCP oder UDP. Hierbei kann optional die Verschlüsselung verwendet werden. Da diese Kommunikationsoperationen normalerweise auf einem einzelnen Edge-Knoten stattfinden, wobei keine Nachrichten vom Host abgehen, ist die Verschlüsselung häufig unnötig.

Alternativ zu den REST-APIs können Sie auch eine Publizierungs- und Subskriptionsschnittstelle verwenden, z. B. die von MQTT bereitgestellte Schnittstelle. Wenn ein Service Daten nur sporadisch bereitstellt, dann ist die Verwendung einer Publizierungs- und Subskriptionsschnittstelle normalerweise einfacher als die wiederholte Abfrage einer REST-API, da bei REST-APIs Zeitlimitüberschreitungen auftreten können. Betrachten Sie beispielsweise einen Service, der eine Hardwaretaste überwacht und eine API für andere Services bereitstellt, mit der festgestellt wird, ob diese Taste gedrückt wurde. Wenn eine REST-API verwendet wird, kann der Aufrufende nicht einfach die REST-API aufrufen und auf eine Antwort warten, die beim Drücken der Taste ausgegeben wird. Wenn die Taste zu lange nicht gedrückt wird, dann tritt für die REST-API eine Zeitlimitüberschreitung auf. Stattdessen müsste der API-Provider umgehend reagieren, um das Auftreten eines Fehlers zu vermeiden. Der Aufrufende muss die API wiederholt und häufig aufrufen, um sicherzustellen, dass das kurze Drücken der Taste nicht übersehen wird. Eine bessere Lösung für den Aufrufenden stellt die Subskription eines passenden Topics bei einem Publizierungs- und Subskriptionsservice bzw. einem entsprechenden Block dar. Daraufhin kann der Aufrufende auf das Publizieren warten, das möglicherweise erst nach geraumer Zeit erfolgt. Der API-Provider kann die Überwachung der Tastenhardware übernehmen und dann lediglich die Statusänderungen für das betreffende Topic publizieren, z. B. `button pressed` (Taste wurde gedrückt) oder `button released` (Taste wurde freigegeben).

Bei MQTT handelt es sich um eines der gängigeren Publizierungs- und Subskriptionstools, die verwendet werden können. Sie können einen MQTT-Broker als Edge-Service bereitstellen und Ihre Publizierungs- und Subskriptionsservices so definieren, dass dieser Service ein erforderlicher Service ist. MQTT wird auch häufig als Cloud-Service verwendet. IBM Watson IoT Platform verwendet beispielsweise MQTT, um mit IoT-Einheiten zu kommunizieren. Weitere Informationen finden Sie unter [IBM Watson IoT Platform](https://www.ibm.com/cloud/watson-iot-platform). Einige der {{site.data.keyword.horizon_open}}-Projektbeispiele verwenden MQTT. Weitere Informationen hierzu finden Sie in den [{{site.data.keyword.horizon_open}}-Beispielen](https://github.com/open-horizon/examples).

Ein weiteres gängiges Publizierungs- und Subskriptionstool ist Apache Kafka, das auch häufig als Cloud-Service eingesetzt wird. {{site.data.keyword.message_hub_notm}}, das im Beispiel `cpu2evtstreams` zum Senden von Daten an {{site.data.keyword.cloud_notm}} verwendet wird, basiert ebenfalls auf Kafka. Weitere Informationen finden Sie unter [{{site.data.keyword.message_hub_notm}}](https://www.ibm.com/cloud/event-streams).

Jeder Edge-Service-Container kann andere lokale Edge-Services auf demselben Host bereitstellen oder nutzen bzw. Edge-Services nutzen, die auf benachbarten Hosts im lokalen LAN bereitgestellt werden. Container können mit zentralen Systemen in einem fernen Rechenzentrum des Unternehmens oder dem Rechenzentrum eines Cloud-Providers kommunizieren. Als Serviceautor legen Sie fest, mit wem und wie Ihre Services kommunizieren können. Verwenden Sie bei der Kommunikation mit Cloud-Provider-Services die Authentifizierungsnachweise wie unter [Developing Secrets](developing_secrets.md)beschrieben, um die Authentifizierungsnachweise einzudämmen.

Es kann nützlich sein, das Beispiel `cpu2evtstreams` erneut zu verwenden, um zu überprüfen, wie der Beispielcode die anderen beiden lokalen Services benutzt. Hierbei kann das Augenmerk auf die Vorgehensweise bei der Angabe von Abhängigkeiten im Beispielcode in den beiden lokalen Services, die Deklaration und Verwendung von Konfigurationsvariablen und die Kommunikation mit Kafka gelegt werden. Weitere Informationen zu diesem Thema finden Sie im Abschnitt zum [Beispiel `cpu2evtstreams`](cpu_msg_example.md).

## Services für privilegierten Modus
{: #priv_services}
Auf einer Hostmaschine können einige Tasks nur von einem Konto mit Rootzugriff ausgeführt werden. Das Äquivalent für Container ist privilegierter Modus. Während Container im Allgemeinen keinen privilegierten Modus auf dem Host benötigen, gibt es einige Anwendungsfälle, in denen dies erforderlich ist. In {{site.data.keyword.ieam}} haben Sie die Möglichkeit, anzugeben, dass ein Service mit aktivierter privilegierter Prozessausführung implementiert werden soll. Die Protokollierung ist standardmäßig inaktiviert. Sie müssen sie explizit in der [Implementierungskonfiguration](https://open-horizon.github.io/anax/deployment_string.html) der jeweiligen Servicedefinitionsdatei für jeden Service aktivieren, der in diesem Modus ausgeführt werden muss. Außerdem muss jeder Knoten, auf dem Sie diesen Service implementieren möchten, auch explizit Container für privilegierte Modi zulassen. Auf diese Weise wird sichergestellt, dass die Knoteneigner eine gewisse Kontrolle darüber haben, welche Services auf ihren Edge-Knoten ausgeführt werden. Ein Beispiel für die Aktivierung der Richtlinie für den privilegierten Modus auf einem Edge-Knoten finden Sie unter [privilegierte Knotenrichtlinie](https://github.com/open-horizon/anax/blob/master/cli/samples/privileged_node_policy.json). Wenn die Servicedefinition oder eine ihrer Abhängigkeiten den privilegierten Modus erfordert, muss die Knotenrichtlinie auch den privilegierten Modus zulassen, oder aber keiner der Services wird nicht auf dem Knoten implementiert. Eine eingehende Beschreibung des privilegierten Modus' finden Sie unter [Was ist der privilegierte Modus und benötige ich ihn?](https://wiki.lfedge.org/pages/viewpage.action?pageId=44171856).


## Servicedefinition
{: #service_definition}

Hinweis: Weitere Informationen zur Befehlssyntax finden Sie im Abschnitt [In diesem Dokument verwendete Konventionen](../getting_started/document_conventions.md).

In jedem {{site.data.keyword.ieam}}-Projekt ist eine Datei `horizon/service.definition.json` vorhanden. Diese Datei definiert Ihren Edge-Service für zwei Zwecke. Einer dieser Zwecke ist es, Ihnen die Simulation der Ausführung Ihres Service mithilfe des Tools `hzn dev` zu ermöglichen. Dieses Tool simuliert eine reale Agentenumgebung, einschließlich der [Netzwerk-Sandbox](#sandbox). Diese Simulation eignet sich zur Erarbeitung spezieller Bereitstellungsanweisungen, beispielsweise Portbindungen und den Zugriff auf Hardwareeinheiten. Die Simulation ist außerdem auch nützlich für die Überprüfung der Kommunikation zwischen Service-Containern in privaten virtuellen Docker-Netzen, die der Agent für Sie erstellt. Der andere Grund für diese Datei besteht darin, Sie in die Lage zu versetzen, Ihren Service auf dem {{site.data.keyword.horizon_exchange}}zu veröffentlichen. In den hier verfügbaren Beispielen wird die Datei `horizon/service.definition.json` im GitHub-Beispielrepository bereitgestellt oder mit dem Befehl `hzn dev service new` generiert.

Öffnen Sie die Datei `horizon/service.definition.json`, die die {{site.data.keyword.horizon}}-Metadaten für eine der Beispielserviceimplementierungen enthält (z. B. [cpu2evtstreams](https://github.com/open-horizon/examples/blob/master/edge/evtstreams/cpu2evtstreams/horizon/service.definition.json)).

Jeder Service, der in {{site.data.keyword.horizon}} veröffentlicht wird, muss einen Namen haben, der ihn innerhalb Ihrer Organisation eindeutig identifiziert. Der Name wird in das Feld `URL` gesetzt und bildet eine global eindeutige Kennung, wenn sie mit Ihrem Organisationsnamen kombiniert wird, und eine bestimmte Implementierung `Version` und Hardware `arch`. Eine vollständige Beschreibung der Servicedefinition finden Sie unter [Servicedefinition](https://github.com/open-horizon/anax/blob/master/docs/service_def.md). Das Beispiel [cpu2evtstreams](https://github.com/open-horizon/examples/blob/master/edge/evtstreams/cpu2evtstreams/horizon/service.definition.json) nutzt einige zusätzliche Features einer grundlegenden Servicedefinition, wie z. B. erforderliche Services und Servicevariablen.

Der Abschnitt `requiredServices` der Datei `horizon/service.definition.json` weist alle Serviceabhängigkeiten auf, die von diesem Service verwendet werden. Mit dem Tool `hzn dev dependency fetch` können Sie Abhängigkeiten zu dieser Liste hinzufügen, so dass Sie die Liste nicht manuell bearbeiten müssen. Nachdem Abhängigkeiten hinzugefügt wurden, werden die anderen `requiredServices` automatisch ausgeführt, wenn der Agent den Container ausführt (z. B. wenn Sie `hzn dev service start` verwenden oder wenn Sie einen Knoten registrieren, auf dem dieser Service implementiert ist). Weitere Informationen zu den erforderlichen Services finden Sie unter [Servicedefinition](https://github.com/open-horizon/anax/blob/master/docs/service_def.md) und [cpu2evtstreams](cpu_msg_example.md).

Im Abschnitt `userInput` deklarieren Sie die Servicevariablen, die Ihr Service verarbeiten kann, um sich für eine bestimmte Implementierung zu konfigurieren. Hier deklarieren Sie Variablennamen, Datentypen und Standardwerte, und Sie können auch eine lesbare Beschreibung für jede einzelne angeben. Wenn Sie `hzn dev service start` verwenden oder wenn Sie einen Edge-Knoten registrieren, auf dem dieser Service implementiert ist, müssen Sie diese Servicevariablen konfigurieren. Das Beispiel [cpu2evtstreams](cpu_msg_example.md) stellt dies durch die Bereitstellung einer Datei `userinput.json` während der Knotenregistrierung dar. Es ist auch möglich, Servicevariablen über Remotezugriff über den CLI-Befehl `hzn exchange node update -f <userinput-settings-file>`festzulegen. Weitere Informationen zu Servicevariablen finden Sie unter [Servicedefinition](https://github.com/open-horizon/anax/blob/master/docs/service_def.md) und [cpu2evtstreams](cpu_msg_example.md).

Im unteren Bereich der Datei `horizon/service.definition.json` ist auch der Abschnitt `deployment` enthalten. Die Felder in diesem Abschnitt benennen jeden Docker-Container, der Ihren logischen Service implementiert. Der Name jedes Containers im Array `Services` ist der DNS-Name, den andere Container verwenden, um den Container auf dem gemeinsam genutzten virtuellen privaten Netz zu identifizieren. Wenn dieser Container eine REST-API zur Nutzung durch andere Container zur Verfügung stellt, können Sie auf diese REST-API innerhalb des nutzenden Containers zugreifen, indem Sie den Befehl `curl http://<name>/<your-rest-api-uri>` verwenden. Im Feld `image` eines Namens wird (wie in DockerHub oder in bestimmten privaten Container-Registrys) eine Referenz auf das zugehörige Docker-Container-Image angegeben. Andere Felder im Abschnitt `Deployment` können verwendet werden, um den Container mit Laufzeitoptionen zu konfigurieren, die Docker zum Ausführen des Containers verwendet. Weitere Informationen finden Sie unter [{{site.data.keyword.horizon}} Implementierungskonfiguration](https://github.com/open-horizon/anax/blob/master/docs/deployment_string.md).

## Nächste Schritte
{: #developing_what_next}

Weitere Informationen zur Entwicklung des Edge-Knoten-Codes finden Sie in der folgenden Dokumentation:

* [Bewährte Verfahren bei der Edge-nativen Entwicklung](best_practices.md)

   Informieren Sie sich über die wichtigen Prinzipien und bewährten Verfahren (Best Practices) bei der Entwicklung von Edge-Services für {{site.data.keyword.ieam}}-Software.

* [{{site.data.keyword.cloud_registry}} verwenden](container_registry.md)

  Mit {{site.data.keyword.ieam}} können Sie Service-Container anstatt im öffentlichen Docker Hub optional in der privaten sicheren IBM Container-Registry speichern. Wenn Sie z. B. über ein Software-Image verfügen, das Assets enthält, die nicht in einer öffentlichen Registry gespeichert werden können, dann können Sie eine private Docker-Container-Registry wie {{site.data.keyword.cloud_registry}} verwenden.

* [APIs](../api/index.md)

  {{site.data.keyword.ieam}} stellt REST-konforme APIs für die Zusammenarbeit bereit und ermöglicht es den Entwicklern und Benutzern Ihrer Organisation, die Komponenten zu steuern.

* [Edge-Service mit Rollback aktualisieren](../using_edge_services/service_rollbacks.md)

  Prüfen Sie weitere Details über die Implementierung einer neuen Version für einen vorhandenen Edge-Service sowie über die bewährten Verfahren bei der Softwareentwicklung in Bezug auf die Aktualisierung von Rollback-Einstellungen in Mustern oder Bereitstellungsrichtlinien.
