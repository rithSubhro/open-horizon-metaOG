---

copyright:
years: 2019
lastupdated: "2019-07-05"

---

{:new_window: target="blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:codeblock: .codeblock}
{:pre: .pre}
{:child: .link .ulchildlink}
{:childlinks: .ullinks}

# Details zur Entwicklung
{: #developing}

Im folgenden Inhalt werden weiterführende Details zu den Verfahren und Konzepten der Softwareentwicklung für {{site.data.keyword.edge_notm}} ({{site.data.keyword.ieam}}) bereitgestellt.
{:shortdesc}

## Einführung
{: #developing_intro}

{{site.data.keyword.edge_notm}} ({{site.data.keyword.ieam}}) wird auf der Open-Source-Software [Open Horizon - EdgeX Project Group](https://wiki.edgexfoundry.org/display/FA/Open+Horizon+-+EdgeX+Project+Group) erstellt.

Mit {{site.data.keyword.ieam}} können Sie sämtliche Service-Container entwickeln, die Sie für Ihre Edge-Maschinen benötigen. Anschließend können Sie Ihren Code kryptografisch signieren und publizieren. Abschließend können Sie Richtlinien in einem {{site.data.keyword.edge_deploy_pattern}} angeben, um die Softwareinstallation sowie die Überwachung und Aktualisierung der Software zu regulieren. Nachdem Sie diese Tasks abgeschlossen haben, können Sie die {{site.data.keyword.horizon_agents}} und {{site.data.keyword.horizon_agbots}} anzeigen, die die Vereinbarungen für die Zusammenarbeit beim Management des Softwarelebenszyklus treffen. Diese Komponenten können anschließend zum vollständig autonomen Management des Softwarelebenszyklus auf Ihren {{site.data.keyword.edge_nodes}} auf Basis des für jeden Edge-Knoten registrierten Bereitstellungsmusters eingesetzt werden. {{site.data.keyword.ieam}} kann auch Richtlinien verwenden, um festzustellen, wo und wann Services und Modelle für maschinelles Lernen autonom bereitgestellt werden sollten. Richtlinien stellen eine Alternative zu Bereitstellungsmustern dar.

Der Softwareentwicklungsprozess in {{site.data.keyword.ieam}} dient primär der Aufrechterhaltung der Systemsicherheit und -integrität und trägt gleichzeitig zur deutlichen Vereinfachung des Aufwands bei, der für das aktive Software-Management auf Ihren Edge-Knoten anfällt. {{site.data.keyword.ieam}} kann auch Richtlinien verwenden, um festzustellen, wo und wann Services und Modelle für maschinelles Lernen autonom bereitgestellt werden sollten. Richtlinien stellen eine Alternative zu Bereitstellungsmustern dar. Sie können Publizierungsprozeduren für {{site.data.keyword.ieam}} in Ihre kontinuierliche Integrations- und Entwicklungspipeline aufnehmen. Wenn die dezentralen autonomen Agenten publizierte Änderungen an der Software oder an einer Richtlinie erkennen (z. B. im {{site.data.keyword.edge_deploy_pattern}} oder der Bereitstellungsrichtlinie), dann leiten die autonomen Agenten selbstständig die erforderlichen Maßnahmen ein, um die Software zu aktualisieren oder um die Richtlinien in Ihrem gesamten Bestand von Edge-Maschinen unabhängig vom Standort der Maschinen durchzusetzen.

## Services und Bereitstellungsmuster
{: #services_deploy_patterns}

{{site.data.keyword.edge_services}} stellen den grundlegenden Baustein für Bereitstellungsmuster dar. Jeder Service kann einzelne oder auch mehrere Docker-Container enthalten. Jeder Docker-Container kann wiederum einzelne oder mehrere Prozesse mit langer Laufzeit enthalten. Diese Prozesse können in nahezu allen Programmiersprachen geschrieben werden und verwenden alle Bibliotheken oder Dienstprogramme. Allerdings müssen die Prozesse für den Kontext eines Docker-Containers entwickelt und in diesem Kontext ausgeführt werden. Diese Flexibilität bedeutet, dass nahezu keine Einschränkungen in Bezug auf den Code gelten, den {{site.data.keyword.ieam}} für Sie verwalten kann. Wenn ein Container ausgeführt wird, dann befindet sich dieser Container in einer sicheren Sandbox. Diese Sandbox schränkt den Zugriff auf Hardwareeinheiten, bestimmte Services des Betriebssystems, das Hostdateisystem und die Hostnetze der Edge-Maschinen ein. Informationen zu den geltenden Sandboxeinschränkungen finden Sie im Abschnitt [Sandbox](#sandbox).

Der Code für das Beispiel `cpu2evtstreams` besteht aus einem Docker-Container, der zwei weitere lokale Edge-Services nutzt. Diese lokalen Edge-Services stellen die erforderlichen Verbindungen mithilfe von HTTP-REST-APIs über lokale private virtuelle Docker-Netze her. Die Namen dieser Services lauten `cpu` und `gps`. Der Agent stellt jeden dieser Services zusammen mit allen Services, die eine Abhängigkeit zu dem jeweiligen Service deklariert haben, in einem separaten privaten Netz bereit. Ein Netz wird für `cpu2evtstreams` und `cpu` erstellt, ein weiteres Netz für `cpu2evtstreams` und `gps`. Umfasst dieses Bereitstellungsmuster einen vierten Service, der ebenfalls an der Nutzung des Service `cpu` teilnimmt, dann wird ein weiteres privates Netz speziell für den Service `cpu` und den vierten Service erstellt. In {{site.data.keyword.ieam}} dient diese Netzstrategie zur Einschränkung des Zugriffs der Services, sodass diese nur auf die anderen Services zugreifen können, die unter `requiredServices` aufgelistet werden, wenn die anderen Services publiziert werden. Im folgenden Diagramm ist das Bereitstellungsmuster für `cpu2evtstreams` dargestellt, wenn das Muster auf einem Edge-Knoten ausgeführt wird:

<img src="../images/edge/07_What_is_an_edge_node.svg" style="margin: 3%" alt="Services in einem Muster">

**Hinweis:** Die Einrichtung von IBM Event Streams ist nur für bestimmte Beispiele erforderlich.

Die beiden virtuellen Netze ermöglichen dem Service-Container für `cpu2evtstreams` den Zugriff auf die REST-APIs, die von den Service-Containern für `cpu` und `gps` bereitgestellt werden. Diese beiden Container verwalten den Zugriff auf die Betriebssystemservices und die Hardwareeinheiten. Obwohl REST-APIs verwendet werden, bestehen noch zahlreiche andere Kommunikationsmöglichkeiten, die Sie verwenden können, um Ihren Services die gemeinsame Nutzung der Daten und der Steuerungsfunktionen zu ermöglichen.

Häufig erweist sich als effektivstes Codemuster für Edge-Knoten die Bereitstellung mehrerer kleiner, unabhängig voneinander konfigurierbarer und bereitstellbarer Services. IoT-Muster (IoT = Internet of Things; Internet der Dinge) arbeiten häufig mit Low-Level-Services, die Zugriff auf die Hardware der Edge-Knoten benötigen. Hierzu gehören beispielsweise Sensoren oder Aktuatoren. Diese Services ermöglichen den gemeinsamen Zugriff auf diese Hardwarekomponenten, die somit von anderen Services genutzt werden können.

Dieses Muster ist dann nützlich, wenn die Hardware exklusiven Zugriff benötigt, um eine sinnvolle Funktion bereitstellen zu können. Der Low-Level-Service kann diese Form des Zugriffs ordnungsgemäß verwalten. Die Rolle der Service-Container für `cpu` und `gps` ähnelt der der Einheitentreibersoftware im Betriebssystem des Hosts, jedoch auf höherer Ebene. Die Segmentierung des Codes in unabhängige kleine Services, wobei einige speziell für den Low-Level-Hardwarezugriff dienen, ermöglicht eine klare Trennung der Zuständigkeiten (sog. Separation of Concerns). Jede Komponente kann frei entwickelt und im Feld unabhängig aktualisiert werden. Drittanbieteranwendungen können ohne Risiko gemeinsam mit Ihren proprietären konventionellen eingebetteten Software-Stacks bereitgestellt werden. Hierzu wird diesen Komponenten selektiv der Zugriff auf bestimmte Hardwareeinheiten oder andere Services ermöglicht.

Ein Bereitstellungsmuster für eine industrielle Steuereinheit kann beispielsweise aus einem Low-Level-Service zur Überwachung der Sensoren für den Energieverbrauch und aus weiteren Low-Level-Services zusammengesetzt sein. Diese anderen Low-Level-Services können zur Steuerung der Aktuatoren zur Stromversorgung der Einheiten genutzt werden, die überwacht werden sollen. Das Bereitstellungsmuster kann außerdem über einen weiteren Top-Level-Service-Container verfügen, der die Services des Sensors und des Aktuators nutzt. Dieser Top-Level-Service kann die Services zur Benachrichtigung der Operatoren oder zur automatischen Stromabschaltung bei Einheiten nutzen, wenn ein von der Norm abweichender Stromverbrauchswert gemessen wird. Dieses Bereitstellungsmuster kann auch einen Protokollservice umfassen, der Sensor- und Aktuatordaten aufzeichnet und archiviert und möglicherweise auch zur Analyse der Daten eingesetzt werden kann. Eine weitere nützliche Komponente eines solchen Bereitstellungsmusters kann ein GPS-Positionsservice sein.

Jeder einzelne Service-Container kann bei einem derartigen Entwurf unabhängig von den anderen Service-Containern aktualisiert werden. Jeder einzelne Service kann außerdem neu konfiguriert und zu anderen sinnvollen Bereitstellungsmustern zusammengestellt werden, ohne dass hierzu Codeänderungen erforderlich sind. Bei Bedarf kann ein Analyseservice eines Drittanbieters zu dem Muster hinzugefügt werden. Diesem Drittanbieterservice kann der Zugriff nur eine bestimmte Gruppe von schreibgeschützten APIs erteilt werden, wodurch der Service von der Interaktion mit den Aktuatoren der Plattform ausgeschlossen wird.

Alternativ hierzu können alle Tasks in diesem Beispiel einer industriellen Steuereinheit in einem einzelnen Service-Container ausgeführt werden. Diese Alternative stellt allerdings meist nicht den besten Ansatz dar, da eine Gruppe kleinerer unabhängiger und miteinander verbundener Services normalerweise eine schnellere Softwareaktualisierung ermöglicht und ein höheres Maß an Flexibilität bietet. Gruppen kleinerer Services bieten häufiger auch eine geringere Störanfälligkeit im Feld. Weitere Informationen zum Entwurf Ihrer Bereitstellungsmuster finden Sie im Abschnitt [Bewährte Verfahren bei der Edge-nativen Entwicklung](best_practices.md).

## Sandbox
{: #sandbox}

Die Sandbox, in der Services ausgeführt werden, beschränkt den Zugriff auf die APIs, die von Ihren Service-Containern bereitgestellt werden. Hierzu wird jeder Service in mindestens einem virtuellen privaten Netz bereitgestellt. Nur den Services, in denen explizit Abhängigkeiten von Ihren Services deklariert sind, wird der Zugriff erteilt. Eine Beschreibung zum Konfigurieren des DNS-Namens Ihres Containers im entsprechenden virtuellen privaten Netz finden Sie unter [Servicedefinition](#service_definition). Andere Prozesse auf dem Host haben normalerweise keinen Zugriff auf diese Services. In ähnlicher Weise haben andere ferne Hosts normalerweise keinen Zugriff auf diese Services, es sei denn, der Service publiziert explizit einen Port für die externe Netzschnittstelle des Hosts.

## Services, die andere Services verwenden
{: #using_services}

Edge-Services verwenden häufig verschiedene API-Schnittstellen, die von anderen Edge-Services bereitgestellt werden, um Daten von diesen anzufordern oder Steuerbefehle an sie zu senden. Diese API-Schnittstellen sind im Allgemeinen HTTP-REST-APIs, wie diejenigen, die von den Low-Level-Services `cpu` und `gps` im Beispiel `cpu2evtstreams` bereitgestellt werden. Allerdings kann der Einsatz dieser Schnittstellen tatsächlich sinnvoll sein, z. B. für gemeinsam genutzten Speicher, TCP oder UDP. Hierbei kann optional die Verschlüsselung verwendet werden. Da diese Kommunikationsoperationen normalerweise auf einem einzelnen Edge-Knoten stattfinden, wobei keine Nachrichten vom Host abgehen, ist die Verschlüsselung häufig unnötig.

Alternativ zu den REST-APIs können Sie auch eine Publizierungs- und Subskriptionsschnittstelle verwenden, z. B. die von MQTT bereitgestellte Schnittstelle. Wenn ein Service Daten nur sporadisch bereitstellt, dann ist die Verwendung einer Publizierungs- und Subskriptionsschnittstelle normalerweise einfacher als die wiederholte Abfrage einer REST-API, da bei REST-APIs Zeitlimitüberschreitungen auftreten können. Betrachten Sie beispielsweise einen Service, der eine Hardwaretaste überwacht und eine API für andere Services bereitstellt, mit der festgestellt wird, ob diese Taste gedrückt wurde. Wenn eine REST-API verwendet wird, kann der Aufrufende nicht einfach die REST-API aufrufen und auf eine Antwort warten, die beim Drücken der Taste ausgegeben wird. Wenn die Taste zu lange nicht gedrückt wird, dann tritt für die REST-API eine Zeitlimitüberschreitung auf. Stattdessen müsste der API-Provider umgehend reagieren, um das Auftreten eines Fehlers zu vermeiden. Der Aufrufende muss die API wiederholt und häufig aufrufen, um sicherzustellen, dass das kurze Drücken der Taste nicht übersehen wird. Eine bessere Lösung für den Aufrufenden stellt die Subskription eines passenden Topics bei einem Publizierungs- und Subskriptionsservice bzw. einem entsprechenden Block dar. Daraufhin kann der Aufrufende auf das Publizieren warten, das möglicherweise erst nach geraumer Zeit erfolgt. Der API-Provider kann die Überwachung der Tastenhardware übernehmen und dann lediglich die Statusänderungen für das betreffende Topic publizieren, z. B. `button pressed` (Taste wurde gedrückt) oder `button released` (Taste wurde freigegeben).

Bei MQTT handelt es sich um eines der gängigeren Publizierungs- und Subskriptionstools, die verwendet werden können. Sie können einen MQTT-Broker als Edge-Service bereitstellen und Ihre Publizierungs- und Subskriptionsservices so definieren, dass dieser Service ein erforderlicher Service ist. MQTT wird auch häufig als Cloud-Service verwendet. IBM Watson IoT Platform verwendet beispielsweise MQTT, um mit IoT-Einheiten zu kommunizieren. Weitere Informationen finden Sie unter [IBM Watson IoT Platform](https://www.ibm.com/cloud/watson-iot-platform). Einige der {{site.data.keyword.horizon_open}}-Projektbeispiele verwenden MQTT. Weitere Informationen hierzu finden Sie in den [{{site.data.keyword.horizon_open}}-Beispielen](https://github.com/open-horizon/examples).

Ein weiteres gängiges Publizierungs- und Subskriptionstool ist Apache Kafka, das auch häufig als Cloud-Service eingesetzt wird. {{site.data.keyword.message_hub_notm}}, das im Beispiel `cpu2evtstreams` zum Senden von Daten an {{site.data.keyword.cloud_notm}} verwendet wird, basiert ebenfalls auf Kafka. Weitere Informationen finden Sie unter [{{site.data.keyword.message_hub_notm}}](https://www.ibm.com/cloud/event-streams).

Jeder Edge-Service-Container kann andere lokale Edge-Services auf demselben Host bereitstellen oder nutzen bzw. Edge-Services nutzen, die auf benachbarten Hosts im lokalen LAN bereitgestellt werden. Container können mit zentralen Systemen in einem fernen Rechenzentrum des Unternehmens oder dem Rechenzentrum eines Cloud-Providers kommunizieren. Als Serviceautor legen Sie fest, mit wem und wie Ihre Services kommunizieren können.

Es kann nützlich sein, das Beispiel `cpu2evtstreams` erneut zu verwenden, um zu überprüfen, wie der Beispielcode die anderen beiden lokalen Services benutzt. Hierbei kann das Augenmerk auf die Vorgehensweise bei der Angabe von Abhängigkeiten im Beispielcode in den beiden lokalen Services, die Deklaration und Verwendung von Konfigurationsvariablen und die Kommunikation mit Kafka gelegt werden. Weitere Informationen zu diesem Thema finden Sie im Abschnitt zum [Beispiel `cpu2evtstreams`](cpu_msg_example.md).

## Servicedefinition
{: #service_definition}

**Hinweis:** Weitere Informationen zur Befehlssyntax finden Sie im Abschnitt [In diesem Dokument verwendete Konventionen](../getting_started/document_conventions.md).

In jedem {{site.data.keyword.ieam}}-Projekt ist eine Datei `horizon/service.definition.json` vorhanden. Diese Datei definiert Ihren Edge-Service aus zwei Gründen. Einer dieser Gründe betrifft die Möglichkeit zur Simulation der Ausführung Ihres Service mit dem Tool `hzn dev`, die ähnlich wie die Ausführung des Service im {{site.data.keyword.horizon_agent}} ist. Diese Simulation eignet sich zur Erarbeitung spezieller Bereitstellungsanweisungen, beispielsweise Portbindungen und den Zugriff auf Hardwareeinheiten. Die Simulation ist außerdem auch nützlich für die Überprüfung der Kommunikation zwischen Service-Containern in privaten virtuellen Docker-Netzen, die der Agent für Sie erstellt. Der zweite Grund für die Verwendung dieser Datei besteht darin, Ihnen die Möglichkeit zum Publizieren Ihres Service bei {{site.data.keyword.horizon_exchange}} zu geben. In den hier verfügbaren Beispielen wird die Datei `horizon/service.definition.json` im GitHub-Beispielrepository bereitgestellt oder mit dem Befehl `hzn dev service new` generiert.

Öffnen Sie die Datei `horizon/service.definition.json`, die die {{site.data.keyword.horizon}}-Metadaten für eine der Beispielserviceimplementierungen enthält (z. B. [cpu2evtstreams](https://github.com/open-horizon/examples/blob/master/edge/evtstreams/cpu2evtstreams/horizon/service.definition.json)).

Jeder Service, der in {{site.data.keyword.horizon}} publiziert wird, muss über einen Wert für `url` verfügen, der ihn innerhalb Ihrer Organisation eindeutig identifiziert. Dieses Feld ist keine URL. Stattdessen bildet das Feld `url` eine GUID (Globally Unique Identifier; global eindeutige ID), wenn sein Wert mit dem Namen Ihrer Organisation, einer speziellen Implementierungsversion (Feld `version`) und dem Wert für das Feld `arch` kombiniert wird. Sie können die Datei `horizon/service.definition.json` bearbeiten, um die entsprechenden Werte für `url` und `version` anzugeben. Verwenden Sie für `version` einen Wert, der im Stil einer semantische Versionierung angegeben ist. Verwenden Sie die neuen Werte, wenn Sie Ihre Service-Container mit einer Push-Operation übertragen, signieren und publizieren. Alternativ hierzu können Sie auch die Datei `horizon/hzn.json` bearbeiten, sodass die Tools alle Variablenwerte ersetzen, die darin gefunden werden, anstatt die Variablenreferenzen zu verwenden, die in der Datei `horizon/service.definition.json` enthalten sind.

Im Abschnitt `requiredServices` der Datei `horizon/service.definition.json` werden die Serviceabhängigkeiten aufgeführt, z. B. andere Edge-Services, die von diesem Container verwendet werden. Mit dem Tool `hzn dev dependency fetch` können Sie Abhängigkeiten zu dieser Liste hinzufügen, ohne dass die Liste manuell bearbeitet werden muss. Nachdem die Abhängigkeiten hinzufügt wurden, werden die unter `requiredServices` aufgeführten erforderlichen Services automatisch ebenfalls ausgeführt, wenn der Agent den Container ausführt. Dies ist z. B. der Fall, wenn Sie `hzn dev service start` verwenden oder einen Knoten für ein Bereitstellungsmuster registrieren, das diesen Service enthält. Weitere Informationen zu erforderlichen Services finden Sie im Abschnitt zu [cpu2evtstreams](cpu_msg_example.md).

Im Abschnitt `userInput` können Sie die Konfigurationsvariablen deklarieren, die Ihr Service zu seiner Konfiguration für eine bestimmte Bereitstellung nutzen kann. Sie geben hier Variablennamen, Datentypen und Standardwerte an und können außerdem auch eine lesbare Beschreibung für diese Werte angeben. Wenn Sie `hzn dev service start` verwenden oder einen Edge-Knoten für ein Bereitstellungsmuster registrieren, das diesen Service enthält, dann müssen Sie die Datei `userinput.json` bereitstellen, in der Werte von Variablen definiert werden, die nicht über Standardwerte verfügen. Weitere Informationen zu den Konfigurationsvariablen unter `userInput` und den Dateien mit dem Namen `userinput.json` finden Sie im Abschnitt zu [cpu2evtstreams](cpu_msg_example.md).

Im unteren Bereich der Datei `horizon/service.definition.json` ist auch der Abschnitt `deployment` enthalten. Der Bereitstellungsabschnitt enthält eine Zuordnung, die als `services` bezeichnet wird, die den DNS-Namen und die Konfiguration für jedes Container-Image definiert, das den logischen Service implementiert. Die DNS-Namen der einzelnen Services, die in der Zuordnung `services` definiert sind, sind mit dem Zuordnungsschlüssel identisch, mit dem die Containerkonfiguration definiert wird. Der DNS-Name wird von anderen Containern verwendet, um ferne APIs zu starten, die von diesem Container gehostet werden. Die DNS-Namen der einzelnen Container müssen innerhalb einer beliebigen Gruppe von zusammenarbeitenden Containern eindeutig sein. Wenn dieser Container beispielsweise eine REST-API zur Nutzung durch andere Container zur Verfügung stellt, können Anwendungen in anderen Containern diese REST-API mithilfe des Befehls `curl http://<dns-name>/<rest-api-uri>` starten. Wenn die Eindeutigkeit des DNS-Namens nicht gewährleistet ist, führt dies zu einem nicht deterministischen Verhalten beim Zugriff auf ferne APIs, die von Containern mit miteinander in Konflikt stehenden Namen in demselben privaten virtuellen Netz gehostet werden. Im Feld `image` eines Namens wird (wie in DockerHub oder in bestimmten privaten Container-Registrys) eine Referenz auf das zugehörige Docker-Container-Image angegeben. Sie können andere Felder im Abschnitt `deployment` verwenden, um die Vorgehensweise des Agenten bei der Anweisung an Docker zur Ausführung des Containers zu ändern. Weitere Informationen finden Sie unter [{{site.data.keyword.horizon}} Implementierungskonfiguration](https://github.com/open-horizon/anax/blob/master/docs/deployment_string.md).

## Nächste Schritte
{: #developing_what_next}

Weitere Informationen zur Entwicklung des Edge-Knoten-Codes finden Sie in der folgenden Dokumentation:

* [Bewährte Verfahren bei der Edge-nativen Entwicklung](best_practices.md)

   Informieren Sie sich über die wichtigen Prinzipien und bewährten Verfahren (Best Practices) bei der Entwicklung von Edge-Services für {{site.data.keyword.ieam}}-Software.

* [{{site.data.keyword.cloud_registry}} verwenden](container_registry.md)

  Mit {{site.data.keyword.ieam}} können Sie Service-Container anstatt im öffentlichen Docker Hub optional in der privaten sicheren IBM Container-Registry speichern. Wenn Sie z. B. über ein Software-Image verfügen, das Assets enthält, die nicht in einer öffentlichen Registry gespeichert werden können, dann können Sie eine private Docker-Container-Registry wie {{site.data.keyword.cloud_registry}} verwenden.

* [APIs](../api/edge_rest_apis.md)

  {{site.data.keyword.ieam}} stellt REST-konforme APIs für die Zusammenarbeit bereit und ermöglicht es den Entwicklern und Benutzern Ihrer Organisation, die Komponenten zu steuern.

* [Edge-Service mit Rollback aktualisieren](../using_edge_services/service_rollbacks.md)

  Prüfen Sie weitere Details über die Implementierung einer neuen Version für einen vorhandenen Edge-Service sowie über die bewährten Verfahren bei der Softwareentwicklung in Bezug auf die Aktualisierung von Rollback-Einstellungen in Mustern oder Bereitstellungsrichtlinien.
